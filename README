Prerequisities: 
Wordcount Jar to be on S3 already, with a certain Main class (see implementation)
Input text file uploaded to S3.
EC2 key has been generated with name 'adrian'

DATA LOCALITY/REDUNDANCY
s3 input splits are read in multiple HTTP range requests. This is simply a way for HTTP to request a portion of the file instead of the 
entire file (for example, GET FILE X Range: byte=0-10000). no need for replication 
VM's can potentially be co-located on a single VM but this is statistically very unlikely due to size of cluster (.5 million)
EBS (attached storage) is available but this does not exist on EMR instances (it does on beanstalk)
HDFS: a cluster with 10 core nodes of type m1.large would have 2833 GB of space available to HDFS: ( 10 nodes x 850 GB per node ) / replication factor of 3.


STARTING 5 mins
Cluster instances
BOOTSTRAPPING 3 mins
config Hadoop (core, site, hdfs, mapred, yarn), 
config Daemons heap, GC (jobtracker, tasktracker, sn, dn)
Run scripts e.g. install applications, e.g. spark shark,;   
RUNNING 1 sec
SHUTTING_DOWN 2 mins
Configure shutdown action;
COMPLETED


For Amazon replication factor is 3 for a cluster of 10 or more nodes, 2 for a cluster 4-9 nodes, and 1 for a cluster with 3 or fewer nodes (same for us?)

Upload 5GB
local -> lab2 1h 53mins
labs2 -> hdfs 2mins
local -> s3   90 mins  (download about same)
s3 -> hdfs 2 nodes   20 mins
s3 -> hdfs 6 nodes   20 mins

EMR WITH S3 data:
6 small nodes = 57 minutes	(2 slots/instance)
6 medium nodes = 33, 26 minutes (2 slots/instance)
6 large nodes = 12,12 mins
12 large nodes = 6.5  minutes
12 xlarge = 4 mins


EMR with HDFS data
6 small = 38 mins
6 medium = 16, 17 mins
6 large nodes = 13, 12 minutes (6/instance)
6 xlarge nodes = 6, 7 mins
12 xlarge 7 mins
$0.480 per Hour, x7, 1 hour

13 small nodes with S3 = 32 mins
13 small nodes with HDFS = 22 mins


LAB
lab1 = (1DN, 10 slots total = 11 mins)


Lab
13/12/10 14:40:14 INFO mapred.JobClient:     Launched reduce tasks=1
13/12/10 14:40:14 INFO mapred.JobClient:     Launched map tasks=41
13/12/10 14:40:14 INFO mapred.JobClient:     Data-local map tasks=41


12 x lar HDFS
2013-12-09 03:30:51,942 INFO org.apache.hadoop.mapred.JobClient (main):     Launched reduce tasks=28
2013-12-09 03:30:51,943 INFO org.apache.hadoop.mapred.JobClient (main):     Launched map tasks=46
2013-12-09 03:30:51,943 INFO org.apache.hadoop.mapred.JobClient (main):     Data-local map tasks=39


12 x small S3
2013-12-09 02:07:45,353 INFO org.apache.hadoop.mapred.JobClient (main):     Launched reduce tasks=28
2013-12-09 02:07:45,353 INFO org.apache.hadoop.mapred.JobClient (main):     Launched map tasks=52
2013-12-09 02:07:45,354 INFO org.apache.hadoop.mapred.JobClient (main):     Data-local map tasks=40



http://docs.aws.amazon.com/ElasticMapReduce/latest/DeveloperGuide/TaskConfiguration.html
Amazon EC2 Instance Name	Mappers	Reducers
m1.small	2	1
m1.medium	2	1
m1.large	4	2 
m1.xlarge	8	4



NOTE - 1 physical node is V powerful...vm's are more splittable
it is free version, can we do this?
